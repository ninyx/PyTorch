{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvlqm7mP5UKwxhGvYRYYDo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninyx/PyTorch/blob/master/Pytorch_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Colab for PyTorch"
      ],
      "metadata": {
        "id": "FX5Y4OWr6myj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check available GPU"
      ],
      "metadata": {
        "id": "2dY3g1IE6ulg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gkcbily2hAG",
        "outputId": "2f1007f2-5528-4328-83b7-1febf37eae0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 13 23:20:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check GPU Access for PyTorch"
      ],
      "metadata": {
        "id": "eMIvoYfH67jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJRdTzqH7ESl",
        "outputId": "584e8980-b150-4497-c1d3-b0dd8eea6bcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HtVixgAq7Mkg",
        "outputId": "14665805-303c-4fc8-96b3-cca09e63c3c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting tensors and models in GPU"
      ],
      "metadata": {
        "id": "XYrAuoQb9ICH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create tensor in CPU\n",
        "tensor = torch.tensor([1,2,3])\n",
        "\n",
        "#Check device of tensor\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "#Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "print(tensor_on_gpu)\n",
        "\n",
        "#Move it back to CPU\n",
        "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "print(tensor_on_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM2kIu0p7bWc",
        "outputId": "6f8c8686-e371-4d9c-9bde-f2051c320112"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n",
            "tensor([1, 2, 3], device='cuda:0')\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end PyTorch Workflow"
      ],
      "metadata": {
        "id": "CxhtAI_z-sec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_be_covered = {1: 'data prep and load',\n",
        "                 2: 'build model',\n",
        "                 3: 'fitting/training model to data',\n",
        "                 4: 'predict and eval model',\n",
        "                 5: 'save and load model',\n",
        "                 6: 'put all together'}"
      ],
      "metadata": {
        "id": "tVZezScA9MfJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # torch neural networks (nn)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0qQYAve95re",
        "outputId": "520b6d86-3511-4da3-a71b-4ac1fac9acdf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Prep and Loading"
      ],
      "metadata": {
        "id": "4L4krajFTYsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create known data using linear regression to make a straight line with known parameters\n",
        "\n",
        "#y = ax + b\n",
        "weight = 0.7 #a \n",
        "bias = 0.3 #b\n",
        "\n",
        "#build a model to estimate weight and bias\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.01\n",
        "X = torch.arange(start, end, step).unsqueeze(dim = 1)\n",
        "y = weight * X + bias\n",
        "\n",
        "print(X[:20], y[:20], len(X), len(y))"
      ],
      "metadata": {
        "id": "MzLPDQuevCfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data (X) for training and test set\n",
        "for_train = int(0.8 * len(X)) # using 80-20 ratio for training and datasets\n",
        "\n",
        "Xtrain, ytrain = X[:for_train], y[:for_train]\n",
        "Xtest, ytest = X[for_train:], y[for_train:]\n"
      ],
      "metadata": {
        "id": "YPv74-kRWZdZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build"
      ],
      "metadata": {
        "id": "_BUt_XUqdFUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}